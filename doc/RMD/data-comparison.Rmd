---
title: "R Notebook"
output: 
  html_notebook:
    toc: true
---

This document serves to compare the data presented in Sydney's original XLSX 
file and the one generated by Sajeewa. He cleaned it up by inserting "unk" for
missing values. Because there was no file trail for this other than his own
comment, I will compare these two.

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = PROJHOME)
```


```{r}
library('tidyverse')
library('readxl')
library('assertr')
library('poppr')
```


## Assertations

Of course, to make sure the data are cromulent, we want to ensure they live up to
our standards of what has been reported. For this, we will use the *assertr*
package, which lets us check our data in various ways. I'm taking the data
presented in the paper thus far to create the assertions.


```{r}
size_ranges <- 
"locus\trange\tn
5-2(F)	318-324	4
6-2(F)	483-495	3
7-2(F)	158-174	7
8-3(H)	244-270	7
9-2(F)	360-382	9
12-2(H)	214-222	5
17-3(H)	342-363	7
20-3(F)	280-282	2
55-4(F)	153-216	10
110-4(H)	370-386	5
114-4(H)	339-416	10
"
sr <- read_tsv(size_ranges) %>%
  separate(range, c("lower", "upper"), sep = "-") # split range into lower and upper bounds
sr
# Making the assertation string.
# To do this, we are using `sprintf()` to print the assert statement:
#   assert(within_bounds(lower, upper), `locus`)
# which means: "assert that the alleles (data) within this locus (variable) are
# within the defined range". 
# 
# The `apply()` function takes a matrix or data frame and applies a given function over each
# row (MARGIN = 1) or column (MARGIN = 2). In this case, we are specifying rows.
# 
# We then collapse all these statements with the pipe operator: %>%
# Then we add the name of the operation to the beginning
assrt_string <- apply(sr, MARGIN = 1, function(x){
    sprintf("  assert(within_bounds(%s, %s), `%s`)", x[2], x[3], x[1]) 
  }) %>% 
  paste(collapse = " %>%\n") %>%
  paste("assert_alleles_within_bounds <- .", ., sep = " %>%\n")
#
# now we can see what this statement looks like
cat(assrt_string)
# here, we evaluate it, making it available for us later on.
eval(parse(text = assrt_string)) 

YEARS <- c("2003", "2004", "2005", "2007", "2008", "2009", "2010", "2012")

STATE <- c("AU", "TS", "FR", "BL", "MX", "NE", "NY", "MN", "MI", "OR", 
           "WA", "CO", "WI", "ID", "CA", "ND")

HOST <- c("Merlot", "Pinto", "redkid", "Beryl", "Bunsi", "37", "38", 
          "11A", "cornell", "G122", "Orion", "PO7104", "PO7863", "WM31", 
          "GH", "BO7104", "Black", "Vista", "SR06233", "BL", "Fuji", "unk", 
          "Zorro", "PO7883", "Emerson", "Weihing", "Yellow")

check_data_cromulence <- . %>%
  chain_start() %>%
  verify(nrow(.) == 366) %>%          # 366 isolates
  verify(has_all_names(sr$locus)) %>% # Has all loci
  assert_alleles_within_bounds %>%    # each locus has alleles within bounds
  assert(in_set(YEARS), Year) %>%     # has all specified years
  assert(in_set(STATE), State) %>%    # has all specified States (incl. countries)
  assert(in_set(HOST), Host) %>%      # has all specified Hosts (incl. countries)
  chain_end(error_fun = warn_report)
```


## Reading in Sydney's data

Sydney's data is stored in excel format, so we have to use readxl to parse it.
First, we want to know what sheets exist.

```{r}
excel_sheets("../Analysis4 ForManu/A1_Copy of binned-genotypes_SE.xlsx")
```

We will be using the GenAlexBinned sheet. From my talks with Sydney, this sheet
contains the SSR data binned into the expected allelels. Note, this sequence of
data input and cleaning was done iteratively and what you are seeing is the 
final result.

There are always quirks with the data when it's in excel. Often, there are too
many rows, so we have to remove them with `slice()`.

> 2017-06-11: This has been fixed in readxl version 1.0

Quirks specific to thse data:

 - GenAlEx format has an extra header region that should be ignored
 - The loci are formatted like so: `110-4(F)`, where the `(F)` part is not 
   informative
 - The header for the strata has extra information
 

 
```{r sydney_data}
syd <- read_excel("../Analysis4 ForManu/A1_Copy of binned-genotypes_SE.xlsx", 
                sheet = "GenAlexBinned", skip = 1) %>%
  select(-1) %>%                # removing first column, which is empty
  gather(locus, allele, -1) %>% # gather all loci into tidy columns
  mutate(locus = trimws(locus)) %>% # remove whitespace in locus names
  mutate(allele = as.integer(allele)) %>% # force alleles to integers
  spread(locus, allele) %>%     # spread data out with individual loci in columns
  separate(iso_st_mcg_org_loc_yr_hst_cult_rep, 
           c("Isolate", "Severity", "MCG", "State", "Source", "Year", "Host"), 
           sep = "_") %>%
  mutate_if(is.character, trimws) %>% # Trim whitespace forom all character columns
  mutate(Severity = as.numeric(Severity)) %>%
  mutate(Source = ifelse(Source == "", "unk", Source)) %>%
  # slice(-n()) %>% # remove last row
  arrange(Isolate) %>%
  check_data_cromulence
syd
```

## Reading in Sajeewa's data

These data can be read in via `reader::read_csv()`

```{r sajeewa_data}
column_specification <- cols(
  Individual = col_character(),
  iso_st_mcg_org_loc_yr_hst = col_character(),
  `5-2(F)` = col_integer(),
  `6-2(F)` = col_integer(),
  `7-2(F)` = col_integer(),
  `8-3(H)` = col_integer(),
  `9-2(F)` = col_integer(),
  `12-2(H)` = col_integer(),
  `17-3(H)` = col_integer(),
  `20-3(F)` = col_integer(),
  `55-4(F)` = col_integer(),
  `110-4(H)` = col_integer(),
  `114-4(H)` = col_integer()
)
saj <- read_csv("../Analysis4 ForManu/A2_Copy4 EUR_AUS_forManu.csv", skip = 2, col_types = column_specification) %>%
  select(-1) %>%
  gather(locus, allele, -1) %>% # gather all loci into tidy columns
  mutate(locus = trimws(locus)) %>% # remove any whitespace in the locus names
  spread(locus, allele) %>%     # spread data out with individual loci in columns
  separate(iso_st_mcg_org_loc_yr_hst, # Note: this corresponds closer to the initial data
           c("Isolate", "Severity", "MCG", "State", "Source", "Year", "Host"), 
           sep = "_") %>%
  mutate_if(is.character, trimws) %>% # Trim whitespace forom all character columns
  mutate(Severity = as.numeric(Severity)) %>%
  arrange(Isolate) %>%
  check_data_cromulence
saj
```

## Comparison


We've sorted each data set by Isolate, so that means that we should expect them
to have the same data. The `setequal()` checks whether or not both data sets
have the same rows (in any order)

```{r, equal_sets}
dplyr::setequal(saj, syd)
```

Okay, something's not cromulent here. We'll have to manaully inspect these:

```{r}
syddiff <- dplyr::setdiff(syd, saj)
sajdiff <- dplyr::setdiff(saj, syd)
the_difference <- bind_rows(syd = syddiff, saj = sajdiff, .id = "source") %>% arrange(Isolate)
head(the_difference, n = 20)
```


## Conclusion

Both data sets failed the cromulence check in a common manner:

```
- Column 'Host' violates assertion 'in_set(HOST)' 2 times
  index  value
1   263 B07104
2   317 PO7683
```

These are the values I grabbed from the manuscript that could possibly match:

 - `PO7863`
 - `PO7883`
 - `BO7104` (The difference is that this is the letter "O" and above is the number "0")

Sydney's data set had an extra discrepancy, but that's noted in the difference
between data sets below:

1. Isolate 805 is flagged for some reason in Sydney's data set
2. Tasmania (TS, Sydney) has been changed to Australia (AU, Sajeewa)
3. Belgium (BL, Sydney) has been changed to France (FR, Sajeewa)
4. Host for isolate 499 has been changed from ExRico (Sydney) to Bunsi (Sajeewa)

### Sydney's comments

We have no clue why 805 is flagged. The changes to the metadata are correct.
The change from BL to FR was because of confusion between the source of the 
collectors vs. source of isolate.

TS was grouped into AU because it was too small of a sample size to do anything.


From here on out, we will use Sajeewa's data for analysis.


## Saving data as genclone object

First we need to transform the data to something that is useable, aka a genclone
object. To avoid confustion with states, we are also transforming the two-letter
abbreviations for France, Mexico, and Australia to the full names. 

```{r}
dat <- saj %>% 
  select(-(Isolate:Host)) %>% 
  df2genind(ind.names = saj$Isolate, 
            strata = select(saj, Severity:Host), # Filtering out severity and Isolate
            ploidy = 1) %>%
  as.genclone()
nameStrata(dat)[3] <- "Region"
pops <- levels(strata(dat)$Region)
levels(strata(dat)$Region) <- case_when(pops == "FR" ~ "France", 
                                        pops == "MX" ~ "Mexico", 
                                        pops == "AU" ~ "Australia", 
                                        TRUE ~ pops)
dat
locNames(dat)
```

### Gathering Repeat Lengths

The repeat lengths were contained in the `A1_Copy of binned-genotypes_SE.xlsx`
spreadsheet in the "replen est" sheet. Because this sheet contained several
merged cells and other oddities, I copy+pasted the relevant data here and 
parsed it from the text.

```{r}
rl <- read_tsv("dinuc			compound			hexinuc			dinuc			dinuc			dinuc			dinuc			trinuc			dinuc			compound			compound			tetranuc			dinuc			tetranuc			tetranuc			tetranuc
(GT)8			[(GT)2GAT]3(GT)14GAT(GT)5[GAT(GT)4]3(GAT)3			(TTTTTC)2(TTTTTG)2(TTTTTC)			(GA)14			(CA)12			(CA)9(CT)9			(CA)9			(TTA)9			(GT)7GG(GT)5			(CA)6(CGCA)2(CAT)2			(CA)7(TACA)2			(TACA)10			(CT)12			(CATA)25			(TATG)9			(AGAT)14(AAGC)4
 5-2(F)	bins	count	 5-3(F)	bins	count	 6-2(F)	bins	count	 7-2(F)	bins	count	 8-3(H)	bins	count	 9-2(F)	bins	count	 12-2(H)	bins	count	 17-3(H)	bins	count	 20-3(F)	bins	count	 36-4(F)	bins	count	 50-4(F)	bins	count	 55-4(F)	bins	count	 92-4(F)	bins	count	 106-4(H)	bins	count	110-4(H)	bins	count	114-4(H)")
  
x <- rl %>%
  select(-starts_with("X")) %>% # removing non-informative columns
  slice(-1) %>%                 # removing first row (repeat patterns)
  gather(replen, locus) %>%
  mutate(replen = strsplit(replen, "_") %>% map_chr(1)) %>% # fix duplicated column names
  mutate(replen = case_when(
    grepl("^di", .$replen)    ~ 2,
    grepl("^tri", .$replen)   ~ 3,
    grepl("^tetra", .$replen) ~ 4,
    grepl("^hex", .$replen)   ~ 6,
    TRUE                      ~ 0.5
  ))

x <- paste("c(", paste(paste0("`", x$locus, "`", " = ", x$replen), collapse = ",\n"), ")", sep = "\n")
cat(x)


repeat_lengths <- eval(parse(text = x))
repeat_lengths <- ifelse(repeat_lengths < 1, 4, repeat_lengths)
repeat_lengths
```

### Adding inconsistent loci

Only 11 loci were manually curated by Sydney and Sajeewa. I'm taking a look at
the other 5 loci because they may be informative. In order to do that, I'm going
to have to clean them up by estimating the the true allele size.

```{r read_excel}
ex <- readxl::read_excel("../Analysis4 ForManu/A1_Copy of binned-genotypes_SE.xlsx", sheet = "GenAlex", skip = 1) %>%
  select(-1) %>%                # removing first column, which is empty
  gather(locus, allele, -1) %>% # gather all loci into tidy columns
  mutate(locus = trimws(locus)) %>% # remove (F) designator
  mutate(allele = as.integer(allele)) %>% # force alleles to integers
  spread(locus, allele)

readr::write_csv(ex, "data/raw_data.csv", col_names = TRUE)

ex <- ex[!names(ex) %in% locNames(dat)]

# Function to select an adjacent allele. It will select the
# next allele if the next allele is not missing and it's distance
# is one away and the previous allele for the same conditions.
# If none of the conditions are met, it will retain the allele.
cromulent_allele <- Vectorize(function(lower, allele, higher){
  if (!is.na(higher) && abs(allele - higher) == 1){
    out <- higher
  } else if (!is.na(lower) && abs(allele - lower) == 1){
    out <- lower
  } else {
    out <- allele
  }
  out
})
ex
exsummary <- ex %>% 
  gather(locus, allele, -1) %>% # tidy the data
  group_by(locus, allele) %>%   
  summarize(n = n()) %>%        # summarize by count 
  ungroup() %>%
  group_by(locus) %>%           # group the loci, add the lower and upper alleles,
  mutate(lower = lag(allele), higher = lead(allele)) %>% # and then create new_alleles
  mutate(new_allele = ifelse(n < 3, cromulent_allele(lower, allele, higher), allele)) %>%
  select(locus, new_allele, allele)
exsummary
```

Now that we have our data set filtered (to a degree), we can merge the data with
`dat` that we defined above.

```{r merging_data}
corrected_loci <- ex %>% gather(locus, allele, -1) %>%
  left_join(exsummary, by = c("locus", "allele")) %>%
  mutate(allele = new_allele) %>%
  select(-new_allele) %>%
  spread(locus, allele) %>%
  separate(iso_st_mcg_org_loc_yr_hst_cult_rep, # Note: this corresponds closer to the initial data
           c("Isolate", "Severity", "MCG", "State", "Source", "Year", "Host"), 
           sep = "_") %>%
  arrange(Isolate) %>%
  select(-(MCG:Host))
datdf <- genind2df(dat, usepop = FALSE) %>% 
  rownames_to_column(var = "Isolate") %>% 
  left_join(corrected_loci, by = "Isolate")
stopifnot(identical(datdf$Isolate, indNames(dat)))
datdf <- datdf[c("Isolate", names(repeat_lengths))]
dat   <- datdf %>% 
  select(-Isolate) %>% 
  df2genind(ind.names = indNames(dat), strata = strata(dat), ploidy = 1) %>% 
  as.genclone()

strata(dat) %>%
  bind_cols(datdf) %>%
  dplyr::as_data_frame() %>%
  readr::write_csv("data/clean_data.csv", col_names = TRUE)
```

The original data includes both Severity and Isolate. Since these are not
necessary for delimiting the strata, we will place them in the "other" slot
after converting Severity to numeric. Placing this information in the "other"
slot ensures that these data will travel with the object.

> Note 2017-06-29: I realized that the severity data was not present in the
> clean data, so I added that in the strata above. To avoid downstream effects,
> I'm additionally removing it from the data set here:

```{r fix_strata}
stopifnot(identical(indNames(dat), saj$Isolate))
other(dat)$meta <- select(saj, Severity, Isolate)
strata(dat) <- select(strata(dat), -Severity)
other(dat)$REPLEN <- fix_replen(dat, repeat_lengths)
```

```{r}
setPop(dat) <- ~Region
dat
locNames(dat)
other(dat)$REPLEN
head(other(dat)$meta)
keeploci <- !locNames(dat) %in% colnames(corrected_loci)
dat11 <- dat[loc = keeploci, mlg.reset = TRUE] # reducing to 11 loci and recalculating mlgs
dat11
```



```{r, save_data}
save(dat, dat11, datdf, keeploci, corrected_loci, file = "data/sclerotinia_16_loci.rda")
```


## Session Information

```{r session_info}
options(width = 100)
devtools::session_info()
```

